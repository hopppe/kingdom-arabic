#!/usr/bin/env python3
"""
Test NLLB-200 model for Arabic-English word translation
This should produce much better results than LibreTranslate's Argos models
"""

import json

# Test words from Mark 1:1 that LibreTranslate got wrong
test_words = [
    "Ù‡ÙØ°ÙÙ‡Ù",      # Should be "this", not "here"
    "Ø¨ÙØ¯ÙØ§ÙŠÙØ©Ù",    # Should be "beginning" âœ“
    "Ø¥ÙÙ†Ù’Ø¬ÙÙŠÙ„Ù",    # Should be "gospel/good news", not "run"!
    "ÙŠÙØ³ÙÙˆØ¹Ù",      # Should be "Jesus" âœ“
    "Ø§Ù„Ù’Ù…ÙØ³ÙÙŠØ­Ù",   # Should be "Christ/Messiah", not "Jesus"
    "Ø§Ø¨Ù’Ù†Ù",       # Should be "son" âœ“
    "Ø§Ù„Ù„Ù‡Ù",       # Should be "God" âœ“
]

# Test words from John 3:16 that LibreTranslate got catastrophically wrong
test_words_jhn = [
    "Ù„Ø£ÙÙ†ÙÙ‘Ù‡Ù",     # Should be "for", not "for him"
    "Ù‡ÙƒÙØ°ÙØ§",       # Should be "so/thus", not "here"
    "Ø£ÙØ­ÙØ¨ÙÙ‘",      # Should be "loved", not "I love"
    "Ø§Ù„Ù„Ù‡Ù",        # Should be "God" âœ“
    "Ø§Ù„Ù’Ø¹ÙØ§Ù„ÙÙ…Ù",   # Should be "the world" âœ“
    "Ø­ÙØªÙÙ‘Ù‰",       # Should be "that/so that", not "even"
    "Ø¨ÙØ°ÙÙ„Ù",       # Should be "gave", not "yes"!!!
    "Ø§Ø¨Ù’Ù†ÙÙ‡Ù",      # Should be "his son" âœ“
    "Ø§Ù„Ù’ÙˆÙØ­ÙÙŠØ¯Ù",   # Should be "only/unique" âœ“
    "ÙŠÙÙ‡Ù’Ù„ÙÙƒÙ",     # Should be "perish", not "hallucinates"!!!
    "ÙƒÙÙ„ÙÙ‘",        # Should be "all/every", not "eat"!!!
]

print("=" * 60)
print("Testing NLLB-200 Model for Arabic-English Translation")
print("=" * 60)

try:
    from transformers import AutoTokenizer, AutoModelForSeq2SeqLM

    print("\nğŸ“¦ Loading NLLB-200 model (this may take a moment)...")
    print("   Model: facebook/nllb-200-distilled-600M")

    model_name = "facebook/nllb-200-distilled-600M"
    tokenizer = AutoTokenizer.from_pretrained(model_name)
    model = AutoModelForSeq2SeqLM.from_pretrained(model_name)

    # NLLB language codes
    # Arabic: ara_Arab
    # English: eng_Latn

    def translate_word(arabic_word):
        """Translate a single Arabic word using NLLB"""
        inputs = tokenizer(arabic_word, return_tensors="pt")

        # Set source and target language codes
        translated_tokens = model.generate(
            **inputs,
            forced_bos_token_id=tokenizer.lang_code_to_id["eng_Latn"],
            max_length=50
        )

        translation = tokenizer.batch_decode(translated_tokens, skip_special_tokens=True)[0]
        return translation

    print("\nâœ… Model loaded successfully!\n")

    print("Testing Mark 1:1 words:")
    print("-" * 60)
    for word in test_words:
        translation = translate_word(word)
        print(f"  {word:15} â†’ {translation}")

    print("\n\nTesting John 3:16 words:")
    print("-" * 60)
    for word in test_words_jhn:
        translation = translate_word(word)
        print(f"  {word:15} â†’ {translation}")

    print("\n" + "=" * 60)
    print("âœ… Test complete!")
    print("=" * 60)

except ImportError:
    print("\nâŒ Error: transformers library not installed")
    print("\nTo install, run:")
    print("  pip install transformers torch sentencepiece")
    print("\nNote: This will download ~600MB model on first run")

except Exception as e:
    print(f"\nâŒ Error: {e}")
    import traceback
    traceback.print_exc()
